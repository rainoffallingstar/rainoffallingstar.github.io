
---

layout: mypost
title: 在DL领域中乳腺超声数据的处理探究
categories: [实验报告]

---

### 在DL领域中乳腺超声数据的处理探究

> by fallingstar 2022-06-18

本实验报告主要探讨超声数据在dl研究方向上的合理数据规模、数据收集与处理方式等目前需要明确的问题。 
#### HIGHTLIGHT
-  在设置良好的任务目标、制作基本精确的数据集的情况下，利用超声数据进行深度学习影像组学表现出了模型拟合的趋势。

-   超声影像最大的问题是数据同质化差，但是深度学习可能无视数据原本的差异性，但是这一切的前提是正确的采集优质数据、制作精确的标签/标注。

-   每组\>=400张病灶图是一个理想的超声数据集的构成，从每个患者中采集5-10张病灶图计算的话，因此每组可能之少需要40-80个病人。

#### 预实验：实验步骤及方法

##### 材料及代码情况

1.  **数据集** 本次使用来着kaggle的乳腺超声数据集，其中包含良性、恶性及正常3类，其中良性440张，恶性230张，正常样本120张，格式为"\*.png"，灰度图像,大小均在500-500左右，质量中等，部分数据带有文字及图像标尺，可能来源于不同的机构及文章，同质性较差。
2.  **代码包**
    1.  R 4.2.0
    2.  keras
    3.  tfhub
    4.  tfdatasets
    5.  tfautograph
    6.  reticulate
    7.  purrr
    8.  fs
3.  **设备** chromebook piexl 2013 （i5-3代）

##### 实验步骤

1.  **预处理** 模型预处理使用随机抽取法将良性子集内抽取240左右以平衡数据集，图像仅轻微增强，包括旋转及缩放。
2.  **迁移学习** 模型采用预训练过的mobilenet进行迁移，重新设计dropout层及分类器，batch_size=5,adam优化学习率，epoch=10。

#### 结果

模型结构如下

```{r models,warning=FALSE}
summary(model)
```
```{r models,warning=FALSE}
Model: "sequential_1"
_________________________________________________________________
 Layer (type)           Output Shape         Param #  Trainable  
=================================================================
 mobilenet_1.00_224 (Fu  (None, 1024)        3228864  Y          
 nctional)                                                       
 dropout_1 (Dropout)    (None, 1024)         0        Y          
 dense_1 (Dense)        (None, 3)            3075     Y          
=================================================================
Total params: 3,231,939
Trainable params: 3,210,051
Non-trainable params: 21,888
```
训练中情况

```{r trainhistory,echo=FALSE,warning=FALSE}
plot(history)
```

```
Epoch 1/20
57/57 [==============================] - 191s 3s/step - loss: 1.7562 - accuracy: 0.4877 - val_loss: 1.4449 - val_accuracy: 0.4500
Epoch 2/20
57/57 [==============================] - 143s 2s/step - loss: 0.9802 - accuracy: 0.6772 - val_loss: 1.9370 - val_accuracy: 0.5643
Epoch 3/20
57/57 [==============================] - 149s 3s/step - loss: 0.9027 - accuracy: 0.6737 - val_loss: 2.8377 - val_accuracy: 0.5214
Epoch 4/20
57/57 [==============================] - 206s 3s/step - loss: 0.7167 - accuracy: 0.7298 - val_loss: 2.1578 - val_accuracy: 0.5929
Epoch 5/20
57/57 [==============================] - 148s 3s/step - loss: 0.5706 - accuracy: 0.7789 - val_loss: 1.5165 - val_accuracy: 0.6214
Epoch 6/20
57/57 [==============================] - 155s 3s/step - loss: 0.5824 - accuracy: 0.8035 - val_loss: 4.7228 - val_accuracy: 0.5286
Epoch 7/20
57/57 [==============================] - 172s 3s/step - loss: 0.6021 - accuracy: 0.7544 - val_loss: 1.0162 - val_accuracy: 0.7643
Epoch 8/20
57/57 [==============================] - 172s 3s/step - loss: 0.4528 - accuracy: 0.8070 - val_loss: 0.9361 - val_accuracy: 0.7857
Epoch 9/20
57/57 [==============================] - 155s 3s/step - loss: 0.4100 - accuracy: 0.8281 - val_loss: 0.9049 - val_accuracy: 0.7286
Epoch 10/20
57/57 [==============================] - 180s 3s/step - loss: 0.4154 - accuracy: 0.8456 - val_loss: 0.9349 - val_accuracy: 0.6857
Epoch 11/20
57/57 [==============================] - 175s 3s/step - loss: 0.4910 - accuracy: 0.8070 - val_loss: 1.6761 - val_accuracy: 0.6643
Epoch 12/20
57/57 [==============================] - 174s 3s/step - loss: 0.4119 - accuracy: 0.8316 - val_loss: 0.8214 - val_accuracy: 0.7929
Epoch 13/20
57/57 [==============================] - 189s 3s/step - loss: 0.3411 - accuracy: 0.8947 - val_loss: 1.0039 - val_accuracy: 0.7500
Epoch 14/20
57/57 [==============================] - 155s 3s/step - loss: 0.3268 - accuracy: 0.8772 - val_loss: 1.0170 - val_accuracy: 0.8000
Epoch 15/20
57/57 [==============================] - 201s 4s/step - loss: 0.2998 - accuracy: 0.8982 - val_loss: 1.1520 - val_accuracy: 0.6857
Epoch 16/20
57/57 [==============================] - 134s 2s/step - loss: 0.3058 - accuracy: 0.8912 - val_loss: 0.6448 - val_accuracy: 0.7929
Epoch 17/20
57/57 [==============================] - 192s 3s/step - loss: 0.3266 - accuracy: 0.8947 - val_loss: 0.5768 - val_accuracy: 0.8143
Epoch 18/20
57/57 [==============================] - 134s 2s/step - loss: 0.3244 - accuracy: 0.8807 - val_loss: 1.1219 - val_accuracy: 0.6786
Epoch 19/20
57/57 [==============================] - 184s 3s/step - loss: 0.3482 - accuracy: 0.8877 - val_loss: 0.7081 - val_accuracy: 0.8071
Epoch 20/20
57/57 [==============================] - 204s 4s/step - loss: 0.2969 - accuracy: 0.9053 - val_loss: 1.2818 - val_accuracy: 0.5786


```
![](https://gitee.com/rainoffallingstar/rainoffallingstar/raw/mydraft/_imgbed/202206181602697.png)
总体上在epoch15时模型达到过拟合。在epoch1-15间表现为收敛趋势。在验证集上准确率徘徊在80%左右，通常提示数据集原始数据不足。

#### 讨论
##### 乳腺超声影像的收集及常用格式

医学超声检查是一种基于超声波的医学影像学诊断技术，使肌肉和内脏器官（包括其大小、结构和病理学病灶）可视化。不同组织和器官之间不同的声学特征导致的声阻抗不同，从而在超声图像中的表现不同。

正常的乳腺超声图像由浅至深可分五层结构：最外层为皮肤，厚2至3mm，呈强回声带；第二层为皮下脂肪，呈低回声，其内可见三角形回声，为CooPer韧带声像；第三层为腺体层，厚1.0cm士3.0cm，呈低回声，其中夹杂有点状及条状回声，为纤维组织、脂肪及导管结构；第四、五层为胸肌及肋间肌，一般易于分辨，呈条状回声（fig.1）

![fig.1](https://img-blog.csdn.net/20170630210536923?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvU3VuZ2Rlbg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

目前已知的超声医学数据格式有两种：dicom及视频格式，相比视频格式而言，dicom格式更加原始，成像质量及截取到的影像横面清晰度可能更好，且标注手段多，对于计算设备处理要求低，而视频格式的成像质量可能与帧数有关，且处理及占用体积较为困难。

然而目前在超声医学方面的优质数据集并不多，可能与超声设备采集影像无法做到同质化有关，如：1.相比ct、mri、x-ray在全身/解剖区域的总体扫描，超声影像更多是在局部进行穿透探查，而每次选点的不同，都将导致图像的显像改变。2.不同设备、不同人种之间可能带来的差异。**但是值得注意的是，通常同质化问题在深度学习中并不是一个严重的问题，因为特定的病灶特征在拓扑空间的投影有可能是相关联的，从而能无视数据原本的差异性，但是这一切的前提是正确的采集优质数据、制作精确的标签/标注。**

##### 处理及数量的问题

1.  在数量上，从本次实验的结果来看，每组\>=400张病灶图是一个理想的超声数据集的构成，从每个患者中采集5-10张病灶图计算的话，因此每组可能之少需要40-80个病人。

2.  在数据处理上，无论dicom格式或者视频格式，我们都建议采取以下步骤进行数据处理：去除四周文字 -\> 保存为".png/.jpg"格式 -\> 重取大小为224-224 -\> 数据增强。

3.  文件目录结构及标注，在未经专业标注软件处理前，一般以文件夹名称作为标注/标签。如： 

#### 超声增强造影影像组学的建议

1.  从训练情况来看：**在设置良好的任务目标、制作基本精确的数据集的情况下，利用超声数据进行深度学习影像组学表现出了模型拟合的趋势。**
2.  **造影增强数据可能比单纯原始灰度超声数据提供更多信息**，可以进一步探究，但仍需要良好的数据集及任务设置。
3.  **在模型选择上仍需要慎重**，应优先选择适合小型数据集的拟合方法，包括迁移学习，在超低数据集时，仍然建议使用SVM分类器进行建模可能效果良好。
